1. What is your cluster size? a)develop b)testing c)production
==> No testing cluster. For develop & prodn same cluster size was there... 128GB RAM per nodes, 15 Nodes cluster, cores per node dont reember exactly.

2. How much data you deal with on a daily basis and in which at time what format did u receive data? and file size of data
==> Data varies daily. But its near around 50-70 GB for some tables. we receive data in csv files from client & from legacy RDBMS system.


3. what are your roles and resposibiities in your project?
==> Already mentioned in project description.. pls refer .

4. What is the configuration of each node in your cluster?
==>  answered in 1st question.

5. What is the big data distribution you use?
==> Cloudera


6. Can you explain how you do the deployment?
==> Deployment handled through CI/CD. DevOps team did set up. we just used it.

7. What is the most challenging things you faced in your project?
==> 1. Requirement gathering while POCs & As a fresher undersanding the requirements clearly & provide solution.
    2. As we aere new in spark, WE faced slow performance issues & we solved it using broadcasting, repartitioning, using orc file formats for storage, using cache() & persist() methods.


8. Did you face any performance issue in your project, how did you overcome it?
==> answered in 7th question. Also data skewness issue solved by repartitioning only.

9. Versions of tools?
     a) hadoop
     b) sqoop
     c) hive
     d) hbase
     e) spark
     f) scala
     g) python

==> this you will get on set up only in INSTALL folder.

10. downstream and upstream sources?
==> upstream is mysql for project 1 & 2. Downstream for project 1 was HBase through which dashboard team we picking data & for project 2, some another team was maintaining dashboards. 

11. team size of your project?
==> 4 people.. 1 with 5 yrs Exp. & 3 freshers.
	Scrum master & Devops people were divided in multiple teams.

12.how many columns in table 
===> This no on asks... this is wrong quesiton. Data size we can tell always. if someone asks then generally u can say dont rermeber.. but 15+ columns.

13.which debug type in ur project 
===> This is wrong quation. If its like how to you monitor job. then you can say spark UI.


14.how did u perform  process of validation input and output 
===> We were doing validation of data After pipeline completion by comapring data with legacy system. basic checks like count of rows, sum of int columns & distinct colunt of String columns.

15.what are  requirements and clarify the doubts with BA.
==> Nothing like BA involes. We were speaking with client & we only gathered requirements. 

16.which query did u perform in  ur project ..
==> Wrng question. e did multiple operations in project. no on will ask which query.

17.which KPI(key perform index) did u perform in ur project 
==> question not clear. If its relasted to performance . then we used python to pull data in 2nd project & we used spark optimisation tehniques..